---
title: "MovieLens Recomendation system Project"
author: "Matias Garcia Mazzaro"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:  
  pdf_document:
    fig_crop: no
    number_sections: yes
    toc: yes
    toc_depth: 3
geometry:
- top=25mm
- bottom=25mm
- left=25mm
- right=25mm
- heightrounded
highlight-style: pygments
linkcolor: blue
mainfont: Arial
fontsize: 12pt
sansfont: Verdana
documentclass: report
urlcolor: blue
---
\pagebreak
# The Project {-}

This is a Machine Learning Project named MovieLens, it is a recomendation system of movies based in 10 millons dataset. The sourse of this work is provided for [Group Lens](https://grouplens.org/datasets/movielens/10m/), presing [here!!](http://files.grouplens.org/datasets/movielens/ml-10m.zip)

This work is part of the final project for the Data Science Professional certificate of HarvardX. In October 2006, Netflix offered a challenge to the data science community: improve our recommendation algorithm by 10% and win a million dollars.

# The Objetive

I will explore the data and construct a model describing the complete process, the method to compare diferents models will be trough RMSE (root mean squared error) between the true data and predicted data. 

We will create a data set that we work and a validation data set. But we need to be sure don't use the validation dataset for define the model. For this cuestion, we will create a data partition of the training data for test it and define the model.

We need obtain a RMSE < 0.86490 in the final validation for the total calification.


# Download and construct the dataset

The Netflix data is not publicly available, but the GroupLens research lab generated their own database with over 20 million ratings for over 27,000 movies by more than 138,000 users.

We start with the cration of **edx** and **validation** objects and loading the packages i will use.
The first step is to load the diferents library we will use.

```{r, warning=FALSE, message=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 3.6 or earlier:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))
# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

# Analysis

For start the project, we have two objets with will work, it is the **edx** (where the information we train and test the model), and **validation** object (for test our model when we finish out analysis)
The fisrt step, is to take **edx** object and make a data partition **train_set** and **test_set**:

## Data partition

```{r}
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.2, 
                                  list = FALSE)
train_set <- edx[-test_index,]
test_set <- edx[test_index,]
```

for be sure there are the same users and movies in the test set and training set;

```{r}
test_set <- test_set %>% 
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")
```

### Exploring the data before to start 

For investigate the dataset we look, how many diferents movies are in the dataset, and how many diferents users.

```{r}
train_set %>% 
  summarize(n_users = n_distinct(userId),
            n_movies = n_distinct(movieId))
```

Also we can observe that the "gendres" variable have differents asociated gendres.

```{r}
head(train_set$genres)
```

We can observe also the distribution density of ratings.

```{r}
edx %>% group_by(rating) %>% ggplot(aes(rating)) + geom_density()
```

## Creation of the RMSE function

With the porpouse of messure the _root mean squared error_ (RMSE), we create the function;

$$RMSE=\sqrt{\frac{1}{N}\sum_{u,i}(\hat{y}_{u,i}-y_{u,i})^2}$$

```{r, echo= TRUE}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}  
```

## The simplest model

The simplest model we can make, is the mean rating more de diferences for movie and user.

$$y_{u,i} = \mu + \epsilon_{u,i}$$

We compute the RMSE.

```{r}
mu_hat <- mean(train_set$rating)
mu_hat

naive_rmse <- RMSE(test_set$rating, mu_hat)
naive_rmse
```

We save the result in a new object for compare results later.

```{r}
rmse_results <- tibble(method = "Just the average", RMSE = naive_rmse)
```

## _Movie effect_

For model the _movie effect_, which implies, a *bias* added to the before model who move the mean for the mean of movie, we write;

$$y_{u,i} = \mu + bi + \epsilon_{u,i}$$

```{r, message=FALSE}
mu <- mean(train_set$rating) 

movie_avgs <- train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))
```

And the distribution of bias is;

```{r, echo=FALSE}
qplot(b_i, data = movie_avgs, bins = 10, color = I("black"))
```

We predict and test;

```{r}
predicted_ratings <- mu + test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  pull(b_i)

movie_effect <- RMSE(predicted_ratings, test_set$rating)
movie_effect
```

We can see, the model including movie effect is better.

## _User effect_

We add to the before model the user effect:

$$y_{u,i} = \mu + bi + bu + \epsilon_{u,i}$$

We observe the distribution of the diferents users;

```{r, echo=FALSE}
train_set %>% 
  group_by(userId) %>% 
  summarize(b_u = mean(rating)) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 30, color = "black")
```

Then, we calculate de average for users;

```{r, message=FALSE}
user_avgs <- train_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))
```

And predict movie effect adding user effect.

```{r}
predicted_ratings <- test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

user_effect <- RMSE(predicted_ratings, test_set$rating)
user_effect
```

Now, we see a sustancially diferent with others model.

## Regularization models

If we explore the data for observe mistakes, we can see easily, there are movies with a fews ratings. Regularization permits us to penalize large estimates that are formed using small sample sizes.
For that we test which Lambda is the optimal ones that aport the minimal RMSE;

```{r, message=FALSE, warning=FALSE}
lambdas <- seq(0, 10, 0.25)

rmses <- sapply(lambdas, function(l){
  
  mu <- mean(train_set$rating)
  
  b_i <- train_set %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  
  b_u <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  
  predicted_ratings <- 
    test_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, test_set$rating))
})
```

We plot the Lambdas & the rmses for see how this affect, then we print the Lambda for the minimum RMSE.

```{r}
qplot(lambdas, rmses)  

lambda_opt <- lambdas[which.min(rmses)]
lambda_opt

regularizated_movie_user <- min(rmses)
```

The optimal Lambda is 4.75 . 

```{r}
min(rmses)
```

And the rmse for Lambda 4.75 is 0.86524.

So, now we have this differents RMSEs

```{r, echo=FALSE}
rmse_results <- tibble(method = c("Just the average", "Movie effect Model", "Movie + User effect Model", "Regularized Movie + User effect Model"), RMSE = c(naive_rmse, movie_effect, user_effect, regularizated_movie_user)) %>% mutate(RMSE = sprintf("%0.5f", RMSE))
rmse_results
```

# Do this better

If we want to do this better, we need to think about the data. We observe, the date where the movie was filmed and the date where was ranked for each users.
Another information we can consider is the gendres of the movies. For all this we need to process original data.

## Data transformation


### Dates transformation

If we look inside the data, we can observe all the titles of the films have the year were was released. It will permit as, after process, add to the models.

```{r}
head(train_set$title)
```

The first step is to add a column with the extraction of this year and count the oldness of the film, and then check it;

```{r}
year_movie <-as.numeric(str_sub(train_set$title, start = -5, end = -2))
train_set <- train_set %>% mutate(year = year_movie)

year_movie <-as.numeric(str_sub(test_set$title, start = -5, end = -2))
test_set <- test_set %>% mutate(year = year_movie)

year_movie <-as.numeric(str_sub(validation$title, start = -5, end = -2))
validation <- validation %>% mutate(year = year_movie)

year_movie <-as.numeric(str_sub(edx$title, start = -5, end = -2))
edx <- edx %>% mutate(year = year_movie)

validation <- validation %>% mutate(Age = 2020 - year)
train_set <- train_set %>% mutate(Age = 2020 - year)
test_set <- test_set %>% mutate(Age = 2020 - year)
edx <- edx %>% mutate(Age = 2020 - year)

head(train_set)
```

Also we need to convert the timestamp in a year of rating.

```{r}
class(validation$timestamp)

validation <- validation %>% mutate(timestamp = as.Date.POSIXct(timestamp))
validation <- validation %>% mutate(year_rating = year(timestamp))

train_set <- train_set %>% mutate(timestamp = as.Date.POSIXct(timestamp))
train_set <- train_set %>% mutate(year_rating = year(timestamp))

test_set <- test_set %>% mutate(timestamp = as.Date.POSIXct(timestamp))
test_set <- test_set %>% mutate(year_rating = year(timestamp))

edx <- edx %>% mutate(timestamp = as.Date.POSIXct(timestamp))
edx <- edx %>% mutate(year_rating = year(timestamp))

head(validation)
```

### Genres transformation

We start we separate the genres and looks;

```{r}
genres <- train_set %>% separate_rows(genres, sep = "\\|")

table_genres <- genres %>% group_by(genres) %>% summarize(n = n(), mean = mean(rating)) %>% arrange(desc(n))

table_genres %>% mutate(genres = reorder(genres, mean)) %>% ggplot(aes(genres,mean,size = n, color = n)) + geom_count() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("Genres Vs Means and rating") + xlab("Genres") + ylab("Means")
```

We can observe how diferents genres affect the mean ratings.

```{r}
table_genres %>% mutate(dif = mean - mean(mean))
```

## Adding the Oldness Movie effect

```{r}

mu <- mean(train_set$rating)
  
b_i <- train_set %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+4.75))
  
b_u <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+4.75))

b_age <- train_set %>%
  left_join(b_i, by="movieId") %>% 
  left_join(b_u, by ="userId") %>%
  group_by(Age) %>% 
  summarize(b_age = mean(rating - b_i - b_u - mu)/(n()+4.75))
  
predicted_ratings <- 
  test_set %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_age, by = "Age") %>%
  mutate(pred = mu + b_i + b_u + b_age) %>%
  pull(pred)

regu_user_movie_age <- RMSE(predicted_ratings, test_set$rating)
```

and compare the results with the before models;

```{r}
rmse_results <- tibble(method = c("Just the average", "Movie effect Model", "Movie + User effect Model", "Regularized Movie + User effect Model", "Regularized Movie + User + Age effect Model"), RMSE = c(naive_rmse, movie_effect, user_effect, regularizated_movie_user, regu_user_movie_age)) %>% mutate(RMSE = sprintf("%0.5f", RMSE))
rmse_results
```

There is not significant results by oldness movie.

## Moving the average in a function

Like we optimize the parameter "Lambda", we will move the mean near the average (mu), is posible there a value who report a better result for the RMSE. We plot the mu vs. rmses.

```{r, message=FALSE, warning= FALSE}

mu <- mean(train_set$rating)+seq(-0.2, 0.7, 0.05)

rmses <- sapply(mu, function(mu){
  
  b_i <- train_set %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+4.75))
  
  b_u <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+4.75))
  b_age <- train_set %>%
    left_join(b_i, by="movieId") %>% 
    left_join(b_u, by ="userId") %>%
    group_by(Age) %>% 
    summarize(b_age = mean(rating - b_i - b_u - mu)/(n()+4.75))
  
  predicted_ratings <- 
    test_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_age, by = "Age") %>%
    mutate(pred = mu + b_i + b_u + b_age) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, test_set$rating))
})

qplot(mu, rmses)  
```

We can see there are a optimal mu over the average.

```{r}
mu <- mu[which.min(rmses)]
mu
regu_user_movie_age_mu <- min(rmses)
```

We add this change in our table.

```{r}
rmse_results <- tibble(method = c("Just the average", "Movie effect Model", "Movie + User effect Model", "Regularized Movie + User effect Model", "Regularized Movie + User + Age effect Model", "Reg. Movie + User + Age effect Model (best mu)"), RMSE = c(naive_rmse, movie_effect, user_effect, regularizated_movie_user, regu_user_movie_age, regu_user_movie_age_mu)) %>% mutate(RMSE = sprintf("%0.5f", RMSE))
rmse_results
```

The new RMSE is better, but in not suficient.

## Add the genre to the model

We will try modeling also the genre, but, instead for each individual genres, for the convination of them. We can see there are near 800 diferent convinations.

```{r}
train_set %>% group_by(genres) %>% summarize(b_gen = mu-mean(rating))
```

We model;

```{r}
mu <- mean(train_set$rating)

b_i <- train_set %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+4.75))

b_u <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+4.75))

b_age <- train_set %>%
  left_join(b_i, by="movieId") %>% 
  left_join(b_u, by ="userId") %>%
  group_by(Age) %>% 
  summarize(b_age = sum(rating - b_i - b_u - mu)/(n()+4.75))

b_gen <- train_set %>% 
  left_join(b_i, by="movieId") %>% 
  left_join(b_u, by ="userId") %>%
  left_join(b_age, by = "Age") %>%
  group_by(genres) %>% 
  summarize(b_gen = sum(rating - b_i - b_u - b_age - mu)/(n()+4.75))

predicted_ratings <- test_set %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_age, by = "Age") %>%
  left_join(b_gen, by = "genres") %>%
  mutate(pred = mu + b_i + b_u + b_age) %>%
  pull(pred)

regu_user_movie_age_gen <- RMSE(predicted_ratings, test_set$rating)
```

We explore the results.

```{r}
rmse_results <- tibble(method = c("Just the average", "Movie effect Model", "Movie + User effect Model", "Regularized Movie + User effect Model", "Regularized Movie + User + Age effect Model", "Reg. Movie + User + Age + Genre effect Model"), RMSE = c(naive_rmse, movie_effect, user_effect, regularizated_movie_user, regu_user_movie_age, regu_user_movie_age_gen)) %>% mutate(RMSE = sprintf("%0.5f", RMSE))
rmse_results
```

Now we obtain a significant result.

We fit again the mu parameter for more presicion.

```{r, message=FALSE, warning=FALSE}
mu <- mean(train_set$rating)+seq(0.1, 0.3, 0.05)


rmses <- sapply(mu, function(mu){
  
  b_i <- train_set %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+4.75))
  
  b_u <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+4.75))
  
  b_age <- train_set %>%
    left_join(b_i, by="movieId") %>% 
    left_join(b_u, by ="userId") %>%
    group_by(Age) %>% 
    summarize(b_age = sum(rating - b_i - b_u - mu)/(n()+4.75))
  
  b_gen <- train_set %>% 
    left_join(b_i, by="movieId") %>% 
    left_join(b_u, by ="userId") %>%
    left_join(b_age, by = "Age") %>%
    group_by(genres) %>% 
    summarize(b_gen = sum(rating - b_i - b_u - b_age - mu)/(n()+4.75))
  
  predicted_ratings <- test_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_age, by = "Age") %>%
    left_join(b_gen, by = "genres") %>%
    mutate(pred = mu + b_i + b_u + b_age) %>%
    pull(pred)

  return(RMSE(predicted_ratings, test_set$rating))
})

qplot(mu, rmses)  
```

```{r}
mu[which.min(rmses)]

regu_user_movie_age_gen_mu <- min(rmses)

rmse_results <- tibble(method = c("Just the average", "Movie effect Model", "Movie + User effect Model", "Regularized Movie + User effect Model", "Regularized Movie + User + Age effect Model", "Reg. Movie + User + Age + Genre effect Model", "Reg. Movie + User + Age + Genre effect Model (mu opt)"), RMSE = c(naive_rmse, movie_effect, user_effect, regularizated_movie_user, regu_user_movie_age, regu_user_movie_age_gen, regu_user_movie_age_gen_mu)) %>% mutate(RMSE = sprintf("%0.5f", RMSE))
rmse_results
```

# Validation

For test our best model, the last one, we need to process now with the validation set. For train our model we will use the complete training set "edx". Like edx have more data can be posible a improvement respect our last training.

We use our optimized parameters.

```{r, message=FALSE, warning=FALSE}
mu <- 3.712482

b_i <- edx %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+4.75))
  
b_u <- edx %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+4.75))
  
b_age <- edx %>%
  left_join(b_i, by="movieId") %>% 
  left_join(b_u, by ="userId") %>%
  group_by(Age) %>% 
  summarize(b_age = sum(rating - b_i - b_u - mu)/(n()+4.75))
  
b_gen <- edx %>% 
  left_join(b_i, by="movieId") %>% 
  left_join(b_u, by ="userId") %>%
  left_join(b_age, by = "Age") %>%
  group_by(genres) %>% 
  summarize(b_gen = sum(rating - b_i - b_u - b_age - mu)/(n()+4.75))
  
predicted_ratings <- validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_age, by = "Age") %>%
  left_join(b_gen, by = "genres") %>%
  mutate(pred = mu + b_i + b_u + b_age) %>%
  pull(pred)

validation_rmse <- RMSE(predicted_ratings, validation$rating)
validation_rmse
```

We obtain a RMSE of our prediction and true data, of 0.8645024.

```{r}
rmse_results <- tibble(method = c("Just the average", "Movie effect Model", "Movie + User effect Model", "Regularized Movie + User effect Model", "Regularized Movie + User + Age effect Model", "Reg. Movie + User + Age + Genre effect Model", "Reg. Movie + User + Age + Genre effect Model (mu opt)", "final model validation"), RMSE = c(naive_rmse, movie_effect, user_effect, regularizated_movie_user, regu_user_movie_age, regu_user_movie_age_gen, regu_user_movie_age_gen_mu, validation_rmse)) %>% mutate(RMSE = sprintf("%0.5f", RMSE))
rmse_results
```

# Conclusion and Results

Exploration data is a process, we start with a very simple model and advance trought we were knowing the data.

In the final validation, obtain a RMSE of **0.86450** , it is better of the objetive (0.86490).


